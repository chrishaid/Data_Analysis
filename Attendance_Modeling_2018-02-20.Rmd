---
title: "Attendance Analysis and Modeling"
author: "Steph Oliva and Chris Haid"
resource_files:
- kipp-chicago-silo-2-aa786970aefd.json
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    fig_width: 10
---
## Motivation

This is a first pass at modeling student-level attendence.  The primary use cases are:

  * to provide predictions of end-of-year average daily attendance (ADA) by for each student earlier in the year (say the middle of the 1st quarter).
  * to provide predictions of end-of-year aveage daily attendance (ADA) by for each school and at the school level earlier in the year (say the middle of the 1st quarter).
  * Prepare for the addition of an On-Track metric in SQRP. 

Another goal is gain familiarity with the [tidymodels](https://github.com/tidymodels) suite of packages (e.g, `recipes`, `parsnip`, `resample`)


The details on pacakges and data we pull are left to the appendix. 

```{r packages, include = FALSE}
library(tidyverse)
library(silounloadr)
library(kippcolors)
library(janitor)
library(lubridate)
library(caret)
library(broom)
library(modelr)
library(tidymodels)
library(kknn)
#library(prophet)

theme_set(theme_kipp_light())


#bigrquery::set_service_token("kipp-chicago-silo-2-aa786970aefd.json")

```

```{r knitr_options, results='hide', echo=FALSE}
knitr::opts_knit$set(comment = FALSE,
                     warning = FALSE, 
                     progress = FALSE, 
                     verbose = FALSE#, 
                     #width = "90%"
                     )
```


```{r att_mem_tables, cache=TRUE, results='hide', echo=FALSE}
membership <- get_powerschool("ps_membership_reg") %>% 
  select(studentid,
         schoolid,
         date = calendardate,
         enrolled = studentmembership,
         grade_level,
         attendance = ATT_CalcCntPresentAbsent,
         yearid) %>%
  filter(yearid >= 25)


attendance <- get_powerschool("attendance") %>% 
  filter(yearid >= 25,
        att_mode_code == "ATT_ModeDaily") 

attendance_code <- get_powerschool("attendance_code") %>%
  mutate(att_code = if_else(att_code == "true", "T", att_code)) %>% 
  select(attendance_codeid = id,
         att_code)
  
  
```


```{r students, cache=TRUE, include=FALSE}
students <- get_powerschool("students") %>% 
  select(studentid = id, 
         student_number,
         gender,
         entrydate,
         schoolentrydate,
         districtentrydate,
         geocode) %>%
  collect()
  
```


```{r joining_tables, results='hide', echo=FALSE, cache=TRUE}
member_att <- membership %>% 
  dplyr::left_join(attendance %>% 
              select(-schoolid,
                        -yearid) %>% 
              dplyr::left_join(attendance_code,
                        by = "attendance_codeid"),
            by = c("studentid",
                   "date" = "att_date")) %>% 
  collect()

```

```{r recoding, results='hide', echo=FALSE}
member_att %>% 
  janitor::tabyl(att_code)

student_att <- member_att %>%
  mutate(enrolled0 = 1,
         enrolled = if_else(att_code == "D" & !is.na(att_code), 0, enrolled0),
         present0 = ifelse(is.na(att_code), 1, 0),
         present1 = ifelse(att_code %in%  c("A", "S"), 0, present0),
         present2 = ifelse(att_code == "H", 0.5, present1),
         present3 = ifelse(att_code %in% c("T", "E", "I"), 1, present2),
         present = ifelse(is.na(present2), 1, present3),
         absent = (1 - present)*enrolled,
         tardy = ifelse(att_code %in% "T", 1, 0),
         dna0 = if_else(att_code == "D", 1, 0),
         dna = if_else(is.na(dna0), 0, dna0)) %>%
  select(yearid,
         schoolid,
         studentid,
         grade_level,
         date,
         att_code,
         enrolled,
         present,
         absent,
         tardy,
         dna)


```




## Quantities of interest
Now we calculate some quantitities of interest: 

* year_end ADA, 
* cumulative ADA by date

```{r cumulative quantities of interest}
yearly_ada <- student_att %>% 
  filter(yearid < 28) %>%
  group_by(yearid,
           studentid) %>% 
  summarize(enrolled = sum(enrolled),
            absent = sum(absent),
            year_end = 1 - (absent/enrolled))
 
cum_ada <- student_att %>% 
  filter(yearid < 28) %>%
  group_by(yearid,
           studentid) %>% 
  arrange(date) %>% 
  mutate(cum_enrolled = cumsum(enrolled),
         cum_absent = cumsum(absent),
         running_ada = 1 - (cum_absent/cum_enrolled)) %>% 
  filter(cum_enrolled > 0)

yearly_cum_ada <- cum_ada %>% 
  select(yearid,
         schoolid,
         grade_level,
         studentid,
         date,
         cum_enrolled,
         cum_absent,
         running_ada) %>% 
  dplyr::left_join(yearly_ada %>% 
              select(-c(enrolled,
                        absent)),
            by = c("yearid",
                   "studentid"))

yearly_cum_ada %>% filter(studentid == 14852)
```

Now we begin doing some subsetting to build a basic model. We'll pull the data for each student over the last few years (excluding SY 18-19) for the last school day in December.  We'll build our model off of this "snapshot". The resulting table shows for each student their number of days enrolled (`cum_enrolled`), days absent (`cum_absent`), ADA through last school day in december (`running_ada`), and the given year's EOY ADA (`year_end`).

### A snapshot in December
```{r dec_subset}
dec_dates <- yearly_cum_ada %>% 
  group_by(yearid) %>% 
  select(date) %>% 
  distinct() %>% 
  filter(lubridate::month(date) == 12) %>% 
  filter(date == max(date))

yca_filtered <- yearly_cum_ada %>% 
  inner_join(dec_dates %>% 
               ungroup() %>% 
               select(-yearid),
             by = c("date")) %>%
  ungroup() %>%
  mutate(yearid = as.factor(yearid),
         schoolid = as.factor(schoolid))


yca_filtered %>%
  ggplot(aes(x = running_ada , y = year_end, color = schoolid)) +
  geom_hline(aes(yintercept = .9)) +
  geom_point(alpha = .7) +
  geom_smooth(se = FALSE) +
  scale_color_kipp() +
  labs(y = "ADA (year end)",
       x = "ADA (last school day in December)",
       color = "School ID #")
```
## Initial Models 

### Linear Mdoel
Our first model (`mod_0`) models year end ADA as a function of cumulative days enrolled and cumulative days absent through the last day of December, using school year as a fixed effect:

$$ y_{i} = f(\alpha + \beta_{e}d_{e} + \beta_{a}d_{a} +\delta_{year} ) $$

We'll first fit a linear model:
```{r lm}

formula_0 <- as.formula(year_end ~ cum_enrolled + cum_absent + yearid)

mod_0 <- lm(formula = formula_0, 
            data = yca_filtered)

summary(mod_0)

  
```
Let's plot the ranked residulas of `mod_0`
```{r plot_residuals_lm}
# yca_filtered %>% 
#   ungroup() %>% 
#   modelr::add_predictions(mod_0) %>% 
#   modelr::add_residuals(mod_0) %>% 
#   arrange(resid) %>% 
#   group_by(yearid) %>% 
#   mutate(rank = row_number(resid)) %>% 
#   ggplot(aes(x = rank, y = resid)) +
#   geom_segment(aes(xend = rank, yend = 0),
#                size = .075, alph=.3) +
#   facet_grid(yearid~.)


plot_ranked_residuals <- function(data,model){
data %>% 
  modelr::add_predictions(model) %>% 
  modelr::add_residuals(model) %>% 
  arrange(resid) %>% 
  group_by(yearid) %>% 
  mutate(rank = row_number(resid)) %>% 
  ggplot(aes(x = rank, y = resid)) +
  geom_segment(aes(xend = rank, yend = 0),
               size = .075, alpha =  .3) +
  facet_grid(yearid~.)

    
}

plot_ranked_residuals(yca_filtered, mod_0)

```
And here are the residuals as a funtion of actuals. 
```{r}
# yca_filtered %>% 
#   ungroup() %>% 
#   modelr::add_predictions(mod_0) %>% 
#   modelr::add_residuals(mod_0) %>% 
#   arrange(resid) %>% 
#   group_by(yearid) %>% 
#   mutate(rank = row_number(resid)) %>% 
#   ggplot(aes(x = year_end, y = resid)) +
#   geom_point(aes(color = cum_enrolled),
#              size = .001) +
#   scale_color_kipp(discrete = FALSE) +
#   facet_grid(yearid ~.)

plot_actual_v_residuals <- function(data, model){
  data %>% 
  ungroup() %>% 
  modelr::add_predictions(model) %>% 
  modelr::add_residuals(model) %>% 
  arrange(resid) %>% 
  group_by(yearid) %>% 
  mutate(rank = row_number(resid)) %>% 
  ggplot(aes(x = year_end, y = resid)) +
  geom_point(aes(color = cum_enrolled),
             size = .001) +
  scale_color_kipp(discrete = FALSE) +
  facet_grid(yearid ~.)
}
  

plot_actual_v_residuals(yca_filtered, mod_0)
```
```{r predicted v actual}
plot_actual_v_predicted <- function(data, model){
  data %>% 
  ungroup() %>% 
  modelr::add_predictions(model) %>% 
  modelr::add_residuals(model) %>% 
  arrange(resid) %>% 
  group_by(yearid) %>% 
  mutate(rank = row_number(resid)) %>% 
  ggplot(aes(x = year_end, y = pred)) +
  geom_point(aes(color = cum_enrolled),
             size = .001) +
  scale_color_kipp(discrete = FALSE) +
  facet_grid(yearid ~.)
}

plot_actual_v_predicted(yca_filtered, mod_0)
```


### Logit
Let's fits these with a logit
```{r logit}
mod_1 <- glm(formula = formula_0,
             family = binomial(link = "logit"),
             data = yca_filtered)

summary(mod_1)

#plot_ranked_residuals(yca_filtered, mod_1)
#plot_actual_v_residuals(yca_filtered, mod_1)

```
```{r}
yca_filtered %>% 
  ungroup() %>%
  modelr::add_predictions(mod_1) %>%
  modelr::add_residuals(mod_1) %>% 
  mutate(pred = exp(pred)/(1+exp(pred)))
```
## Model Evaulation 

We need to partition in train and test to better evaluate our models.  

We'll take [rsample](tidymodels.github.io/rsample) for a spin!

```{r rsample}
yca_split <- yca_filtered %>%
  rsample::initial_split(prop = .75)

yca_train <- analysis(yca_split)
yca_test <- assessment(yca_split)


mod_lm_train <- lm(formula = formula_0, data = yca_train)

yca_augmented <- broom::augment(mod_lm_train, 
                                newdata = yca_test) %>%
  mutate(resid = year_end - .fitted)

yca_augmented %>% 
  ggplot(aes(x = year_end, y = .fitted)) +
  geom_point(aes(color = cum_enrolled, size = -cum_enrolled)) +
  geom_abline(aes(intercept = 0, slope = 1)) +
  facet_grid(yearid~.) +
  scale_color_kipp(discrete = FALSE)

```
```{r size by se}
yca_augmented %>% 
  ggplot(aes(x = year_end, y = .fitted)) +
  geom_point(aes(color = cum_enrolled, size = .se.fit, shape = cum_absent>=16)) +
  geom_abline(aes(intercept = 0, slope = 1)) +
  facet_grid(yearid~.) +
  scale_color_kipp(discrete = FALSE)
```


```{r}
formula_0 <- as.formula(year_end ~ cum_enrolled + cum_absent + yearid)

mod_0 <- lm(formula = formula_0, 
            data = yca_filtered)

formulas <- list(
  as.formula(year_end ~ cum_enrolled + cum_absent),
  as.formula(year_end ~ cum_enrolled + cum_absent + yearid),
  as.formula(year_end ~ cum_enrolled + cum_absent + yearid + schoolid))

list_names <- formulas %>% 
  map_chr(deparse)

names(formulas) <- list_names

set.seed(1234)
rs_data <- vfold_cv(yca_filtered, v = 10, repeats = 3)

holdout_test <- function(splits, ...){
  model <- lm(..., 
              data = splits)
  
  holdout <- assessment(splits)
  
  res <- broom::augment(model, newdata = holdout)
  
  res
}

map_holdout <- function(data, formula){
  data$results <- map(data$splits,
                holdout_test,
                formula)
  
  data$mod_id <- as.character(deparse(formula))
  
  data

}

run_models <- formulas %>% 
  map(~{map_holdout(rs_data, .x) %>% 
      as_tibble()})

calc_rmse <- run_models %>% 
map_df(~mutate(.x, 
            rmse_0 = map2_dbl(results, 
                              results, 
                              ~rmse_vec(.x$year_end, 
                                        .y$.fitted))))


summarize_rmse <- calc_rmse %>% 
  group_by(mod_id) %>% 
  summarize(avg_rmse = mean(rmse_0))


summarize_rmse
```


```{r holdout}

holdout_model_spec <- function(splits, model_type, formula, ...){
  if(tolower(model_type) == "linear"){
    model_spec <- linear_reg() %>% 
      set_engine("lm")
    model <- model_spec %>% 
      fit(formula, 
          data = as.data.frame(splits)) #parsnip wants df
  
  } 
  
  if(tolower(model_type) == "logistic"){
    model_spec <- logistic_reg() %>%
      set_engine("glm")
    model <- model_spec %>% 
      fit(formula,
          data = as.data.frame(splits))

  }
  
  ##Requires additional set of variables: mtry, ntrees
  # if(tolower(model_type) == "random_forest"){
  #   model_spec <- rand_forest() %>% 
  #     set_engine("rand_forest")
  #   model <- model_spec %>% 
  #     fit(..., 
  #         data = splits)
  # 
  # }
  
  if(tolower(model_type) == "knn") {
    model_spec <- nearest_neighbor(mode = "regression", ...) %>%
      set_engine("kknn")
    
    model <- model_spec %>%
      fit(formula, data = as.data.frame(splits))
  }
  holdout <- assessment(splits) 
  
  
  if(model_type == "knn") {
    predictions <- predict(model, new_data = holdout) #won't work with parsnip models
    res <- bind_cols(holdout, predictions) %>%
      rename(.fitted = .pred) %>%
      mutate(.se.fit = as.numeric(NA)) # can't seem to figure out this calcualtion KNN 
    
  args <- list(...)
  model_type <- sprintf("%s %s", model_type, args$neighbors)
  } else {
    res <- broom::augment(model$fit, newdata = holdout) #won't work with parsnip models
  }
  
  
  
  
  # Convert log-odds to probability measure 
  if(tolower(model_type) == "logistic") {
    res <- res %>% mutate(.fitted = exp(.fitted)/(1+exp(.fitted)))
  }
  
  res <- res %>% mutate(model = deparse(formula),
                 model_type = model_type)
  
  splits$results <- res
  
}


holdout_model_spec(rs_data$splits[[1]], "linear", formula_0) #works!
holdout_model_spec(rs_data$splits[[1]], "logistic", formula_0) 


x<-holdout_model_spec(rs_data$splits[[1]], "knn", formula_0, neighbors = 5)

x

```


## Cross-validated models {.tabset}
Let's do a bunch of paramaterizations though Steph's `holdout_model_spec` function.  To do this we need a function that can take a `rsample` splits object and then a list of paramterizations. We'll do one model type (linear model, logistic, KNN) one at a time.

The output should have the average RMSE for each model, as well as any other modeling output. 

```{r holdout_infrastructure, include = FALSE}

holdout_model_splits <- function(data, type, formula, ...){
  out <-data$splits %>% 
    map(holdout_model_spec, type, formula, ...) 

  out
  }

x<-holdout_model_splits(rs_data, "linear", formula_0)  

x$`1`
```
Okay, let's do three things: LM, logistic, and then KNN (with 3, 5, and 10 nearest neighbors):

### Linear Models
```{r lms}
x_lm <- formulas %>%
  map(~{holdout_model_splits(rs_data, "linear", .)})

x_lm_fit_summary <- x_lm %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
          ) 

```
### Logistic
```{r logistic, warning = FALSE}
x_logistic <- formulas %>%
  map(~{holdout_model_splits(rs_data, "logistic", .)})

x_logistic_fit_summary <- x_logistic %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
          ) 
```

### KNN

```{r}

# 3 neighbors
x_knn_3 <- formulas %>%
  map(~{holdout_model_splits(rs_data, "knn",  ., neighbors=3)})

x_knn_3_fit_summary <- x_knn_3 %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
          ) 

# 5 neighbors

x_knn_5 <- formulas %>%
  map(~{holdout_model_splits(rs_data, "knn",  ., neighbors=5)})

x_knn_5_fit_summary <- x_knn_5 %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
  )

# 10 neighbors
x_knn_10 <- formulas %>%
  map(~{holdout_model_splits(rs_data, "knn",  ., neighbors=10)})

x_knn_10_fit_summary <- x_knn_10 %>% 
  map_df( . %>%
            map_df( . %>%  
                      summarize(rmse = rmse_vec(truth = year_end, estimate = .fitted), 
                                model =unique(model), 
                                model_type = unique(model_type)))
  )

x_knn_fit_summary <- bind_rows(x_knn_3_fit_summary, x_knn_5_fit_summary, x_knn_10_fit_summary)
```

Now we bring all the `x_*_fit_summary` tables together and plot the results:

```{r plot fits}
x_fit_summary <- bind_rows(x_lm_fit_summary, 
                           x_logistic_fit_summary, 
                           x_knn_fit_summary)

x_fit_summary
```
## Plotting RMSE
```{r plot_avg_rmse}
x_fit_summary %>%
  group_by(model, model_type) %>%
  summarize(mean_rmse = mean(rmse)) %>%
  arrange(desc(mean_rmse)) %>%
  ungroup() %>%
  mutate(model = fct_inorder(model),
         model_type = fct_inorder(model_type)
         ) %>%

  ggplot() +
  geom_point(aes(x = model, y = mean_rmse, color= model_type), show.legend = FALSE) +
  geom_segment(aes(x = model,xend = model, y = mean_rmse, yend=0, color= model_type), show.legend = FALSE) +
  facet_grid(model_type ~ .) +
  coord_flip() + 
  scale_color_kipp() +
  labs(x = "Model",
       y = "Root Mean Squared Error")
```
```{r}
x_fit_summary %>%
  #group_by(model_type, model) %>%
arrange(rmse) %>%
  ungroup() %>%
  mutate(model = fct_inorder(model),
         model_type = fct_inorder(model_type)
         ) %>%
ggplot() +
  geom_violin(aes(y = rmse, 
                  x = model,
                  fill = model_type
                  ), show.legend = FALSE) +
  geom_point(data = x_fit_summary %>% 
               group_by(model, model_type) %>% 
               summarize(rmse = mean(rmse)), 
             aes(x = model, y = rmse), 
             show.legend = FALSE) +
  geom_linerange(data = x_fit_summary %>% 
               group_by(model, model_type) %>% 
               summarize(y_min = mean(rmse) - 1*sd(rmse), 
                         y_max = mean(rmse) + 1*sd(rmse)), 
             aes(x = model, ymin = y_min, ymax = y_max), 
             show.legend = FALSE) +
  facet_grid(model_type ~ .) +
  coord_flip() + 
  scale_fill_kipp()
  labs(x = "Model",
       y = "Root Mean Squared Error")

```

```{r}
x_fit_summary %>%
ggplot(aes(x=rmse)) +
  geom_density(aes(fill = model_type), show.legend = FALSE) +
  
   geom_segment(data = x_fit_summary %>% 
               group_by(model, model_type) %>% 
               summarize(x_min = mean(rmse) - 1*sd(rmse), 
                         x_max = mean(rmse) + 1*sd(rmse)), 
             aes(y = 0, yend=0, x = x_min, xend = x_max),
             size = 1.25,
             color = kipp_colors$darkgray,
             show.legend = FALSE) +
  
  geom_point(data = x_fit_summary %>% 
               group_by(model, model_type) %>% 
               summarize(rmse = mean(rmse)), 
             aes(x = rmse, y = 0), 
             show.legend = FALSE,
             shape = 21, 
             fill = "white",
             color = kipp_colors$darkgray) +
  
  facet_grid(model ~ model_type, switch = "y") + 
  scale_fill_kipp() +
  theme(strip.text.y = element_text(angle = 180),
        axis.text.x = element_text(angle = 45))  +
  labs(y = "Model",
       x = "Root Mean Squared Error")
  
```


## Appendix 

### Packages and settings
```{r packages_append, ref.label='packages', echo=TRUE, results='markup'}

```
```{r knitr_append, ref.label='knitr_options', echo=TRUE, results='markup'}

```

### Getting data
Here we grab basic attendances and enrollment data from Silo (our warehouse):




```{r att_mem_tables_append, ref.label='att_mem_tables', echo=TRUE, results='markup'}

```

Now we join our daily membership and attendance tables and do some pre-processing. 
```{r joining_append, ref.label='joining_tables', echo=TRUE, results='markup'}

```

Recoding enrollment and attendance data:
```{r recoding_append, ref.label='recoding', echo=TRUE, results='markup'}
```

Getting student data:
```{r student_append, ref.label="students"}

```

